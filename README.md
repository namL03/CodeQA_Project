# CodeQA: Seq2seq Model for Source Code Comprehension

A PyTorch implementation of a Seq2seq model with attention and copy mechanism for answering natural language questions about source code.

## ğŸ“‹ Project Overview

This project implements a baseline Seq2seq model following the methodology from the paper:
**"CodeQA: A Question Answering Dataset for Source Code Comprehension"**

### Task
Given a code snippet and a free-form question about that code, generate an answer to the question.

**Example:**
```
Question: What does this function do?
Code: def add ( a , b ) : return a + b
Answer: adds two numbers
```

## ğŸ—ï¸ Project Structure

```
Code_QA_Project/
â”œâ”€â”€ data/                          # Dataset (not in git - setup locally)
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ train.question
â”‚   â”‚   â”‚   â”œâ”€â”€ train.code
â”‚   â”‚   â”‚   â””â”€â”€ train.answer
â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â””â”€â”€ test/
â”‚   â””â”€â”€ java/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ dev/
â”‚       â””â”€â”€ test/
â”œâ”€â”€ src/                           # Core library code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py            # Dataset loading
â”‚   â”œâ”€â”€ vocabulary.py             # Vocabulary builder
â”‚   â””â”€â”€ dataset.py                # PyTorch Dataset (TODO)
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â””â”€â”€ build_vocabulary.py       # Build vocab from training data
â”œâ”€â”€ saved_models/                  # Trained models & vocabularies
â”‚   â”œâ”€â”€ vocab_python.pkl          # (generated, not in git)
â”‚   â””â”€â”€ vocab_java.pkl            # (generated, not in git)
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for exploration
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Setup Instructions

### On Your Company Computer (Already Done âœ…)
You've already set up the project and built vocabularies.

### On Your Home Laptop (First Time Setup)

#### 1. Clone the repository
```bash
git clone https://github.com/YOUR_USERNAME/CodeQA_Project.git
cd CodeQA_Project
```

#### 2. Set up Python environment
```bash
# Create virtual environment
python -m venv codeqa_venv

# Activate it
# On Windows:
codeqa_venv\Scripts\activate
# On Mac/Linux:
source codeqa_venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Set up data
Since you already have the data at home, just make sure it's in the correct location:
```
data/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ dev/
â”‚   â””â”€â”€ test/
â””â”€â”€ java/
    â”œâ”€â”€ train/
    â”œâ”€â”€ dev/
    â””â”€â”€ test/
```

#### 4. Build vocabularies
```bash
python scripts/build_vocabulary.py
```

This will create:
- `saved_models/vocab_python.pkl`
- `saved_models/vocab_java.pkl`

## ğŸ“ Model Architecture (TODO)

Following the Seq2seq baseline from the CodeQA paper:

- **Encoder**: Bi-LSTM to read `[CLS] Question [SEP] Code`
- **Attention Mechanism**: Allows decoder to focus on relevant parts
- **Copy Mechanism**: Enables copying words from input
- **Decoder**: LSTM to generate the answer

## ğŸ”§ Usage

### Build Vocabulary (Preprocessing)
```bash
python scripts/build_vocabulary.py
```

### Train Model (TODO)
```bash
python scripts/train.py --language python --epochs 20
```

### Evaluate Model (TODO)
```bash
python scripts/evaluate.py --model saved_models/model_python.pt
```

## ğŸ“Š Dataset Statistics

**Python:**
- Training: 56,085 examples
- Vocabulary: 79,071 tokens

**Java:**
- Training: 95,778 examples
- Vocabulary: 32,908 tokens

## ğŸ¯ Key Design Decisions

1. **Separate models for Python and Java** - Following the original paper
2. **Training data only for vocabulary** - Proper ML practice, no test leakage
3. **Min frequency threshold = 2** - Filter rare words to reduce vocabulary size
4. **Tokenized code** - Using code tokens (not AST) as per paper findings

## ğŸ“š References

- CodeQA Paper: "CodeQA: A Question Answering Dataset for Source Code Comprehension"
- Seq2seq: Sutskever et al., 2014
- Copy Mechanism: "Get To The Point" (See et al., 2017)

## ğŸ”„ Git Workflow

### At work (after making changes):
```bash
git add .
git commit -m "Description of changes"
git push
```

### At home (before starting work):
```bash
git pull
```

## âš ï¸ Important Notes

- The `data/` folder is NOT in git (too large)
- Vocabulary `.pkl` files are NOT in git (regenerate locally)
- Always rebuild vocabularies after cloning: `python scripts/build_vocabulary.py`

## ğŸ“§ Contact

Your Name - Your Email

## ğŸ“„ License

MIT License (or your choice)
